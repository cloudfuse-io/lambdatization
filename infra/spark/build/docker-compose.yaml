version: "3.9"
services:
  spark:
    build: .
    image: cloudfuse-io/l12n:spark
    cap_drop:
      - ALL
    read_only: true
    volumes:
      - spark-tmp:/tmp
    entrypoint:
      - python3
      - lambda-handler.py
    environment:
      - AWS_ACCESS_KEY_ID=$L12N_S3_AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$L12N_S3_AWS_SECRET_ACCESS_KEY
      - AWS_REGION=us-east-2
      - DATA_BUCKET_NAME

volumes:
  spark-tmp:
